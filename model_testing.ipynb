{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "dce2918f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data essentials\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "#self created tools\n",
    "from getting_data import *\n",
    "from Indicators import *\n",
    "from y_engineering import *\n",
    "from metric import *\n",
    "from models import *\n",
    "\n",
    "# PyTorch model and training necessities\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#sklearn\n",
    "from sklearn.metrics import *\n",
    "\n",
    "#visualisation with tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e80e42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use gpu if available\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb8eebe8-9d48-4959-bdd0-ee4d1fa564c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtaining data\n",
    "df = pd.read_csv(\"appl_clean_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f142c34-9931-4f58-8c6a-4fefb11af187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# addig some features\n",
    "df['y_binary_sma5'] = (sma(df, period=5, column='Adj Close').shift(periods=-5) > df['Adj Close']).astype(int)\n",
    "ema(df, period=21, column='Adj Close', inplace=True)\n",
    "ema(df, period=200, column='Adj Close', inplace=True)\n",
    "df[\"ema_pct_21\"] = pct_log(df, y_col='ema_21', time_to_pred = 1, pct=True, log=False)\n",
    "df[\"ema_pct_200\"] = pct_log(df, y_col='ema_200', time_to_pred = 1, pct=True, log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07cfc459-915f-4a59-9c47-d2e0506cb1ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>pct_log</th>\n",
       "      <th>pct</th>\n",
       "      <th>y_binary_sma5</th>\n",
       "      <th>ema_21</th>\n",
       "      <th>ema_200</th>\n",
       "      <th>ema_pct_21</th>\n",
       "      <th>ema_pct_200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.789849</td>\n",
       "      <td>459177600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.789849</td>\n",
       "      <td>0.789849</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.809797</td>\n",
       "      <td>597643200</td>\n",
       "      <td>-0.105724</td>\n",
       "      <td>0.025255</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800298</td>\n",
       "      <td>0.799873</td>\n",
       "      <td>0.013229</td>\n",
       "      <td>0.012691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.862517</td>\n",
       "      <td>1831132800</td>\n",
       "      <td>-0.298956</td>\n",
       "      <td>0.065103</td>\n",
       "      <td>0</td>\n",
       "      <td>0.823043</td>\n",
       "      <td>0.820963</td>\n",
       "      <td>0.028420</td>\n",
       "      <td>0.026367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.845894</td>\n",
       "      <td>495924800</td>\n",
       "      <td>0.131580</td>\n",
       "      <td>-0.019273</td>\n",
       "      <td>0</td>\n",
       "      <td>0.829596</td>\n",
       "      <td>0.827290</td>\n",
       "      <td>0.007963</td>\n",
       "      <td>0.007706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.807423</td>\n",
       "      <td>440876800</td>\n",
       "      <td>0.278119</td>\n",
       "      <td>-0.045480</td>\n",
       "      <td>1</td>\n",
       "      <td>0.824279</td>\n",
       "      <td>0.823237</td>\n",
       "      <td>-0.006410</td>\n",
       "      <td>-0.004899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>65.139717</td>\n",
       "      <td>84020400</td>\n",
       "      <td>0.004179</td>\n",
       "      <td>0.017534</td>\n",
       "      <td>0</td>\n",
       "      <td>63.019752</td>\n",
       "      <td>52.204988</td>\n",
       "      <td>0.003375</td>\n",
       "      <td>0.002496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>64.631065</td>\n",
       "      <td>105207600</td>\n",
       "      <td>-0.001877</td>\n",
       "      <td>-0.007809</td>\n",
       "      <td>0</td>\n",
       "      <td>63.166235</td>\n",
       "      <td>52.328630</td>\n",
       "      <td>0.002324</td>\n",
       "      <td>0.002368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>65.499199</td>\n",
       "      <td>65235600</td>\n",
       "      <td>0.003201</td>\n",
       "      <td>0.013432</td>\n",
       "      <td>0</td>\n",
       "      <td>63.378322</td>\n",
       "      <td>52.459681</td>\n",
       "      <td>0.003358</td>\n",
       "      <td>0.002504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>65.354912</td>\n",
       "      <td>46617600</td>\n",
       "      <td>-0.000527</td>\n",
       "      <td>-0.002203</td>\n",
       "      <td>0</td>\n",
       "      <td>63.558012</td>\n",
       "      <td>52.587992</td>\n",
       "      <td>0.002835</td>\n",
       "      <td>0.002446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>64.599274</td>\n",
       "      <td>94487200</td>\n",
       "      <td>-0.002782</td>\n",
       "      <td>-0.011562</td>\n",
       "      <td>0</td>\n",
       "      <td>63.652672</td>\n",
       "      <td>52.707507</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>0.002273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5001 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Adj Close      Volume   pct_log       pct  y_binary_sma5     ema_21  \\\n",
       "0      0.789849   459177600       NaN       NaN              1   0.789849   \n",
       "1      0.809797   597643200 -0.105724  0.025255              1   0.800298   \n",
       "2      0.862517  1831132800 -0.298956  0.065103              0   0.823043   \n",
       "3      0.845894   495924800  0.131580 -0.019273              0   0.829596   \n",
       "4      0.807423   440876800  0.278119 -0.045480              1   0.824279   \n",
       "...         ...         ...       ...       ...            ...        ...   \n",
       "4996  65.139717    84020400  0.004179  0.017534              0  63.019752   \n",
       "4997  64.631065   105207600 -0.001877 -0.007809              0  63.166235   \n",
       "4998  65.499199    65235600  0.003201  0.013432              0  63.378322   \n",
       "4999  65.354912    46617600 -0.000527 -0.002203              0  63.558012   \n",
       "5000  64.599274    94487200 -0.002782 -0.011562              0  63.652672   \n",
       "\n",
       "        ema_200  ema_pct_21  ema_pct_200  \n",
       "0      0.789849         NaN          NaN  \n",
       "1      0.799873    0.013229     0.012691  \n",
       "2      0.820963    0.028420     0.026367  \n",
       "3      0.827290    0.007963     0.007706  \n",
       "4      0.823237   -0.006410    -0.004899  \n",
       "...         ...         ...          ...  \n",
       "4996  52.204988    0.003375     0.002496  \n",
       "4997  52.328630    0.002324     0.002368  \n",
       "4998  52.459681    0.003358     0.002504  \n",
       "4999  52.587992    0.002835     0.002446  \n",
       "5000  52.707507    0.001489     0.002273  \n",
       "\n",
       "[5001 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b651d0ba-db8d-4626-a77f-5fc2b17e0a5e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_xy(df, period, x_col = ['pct'], y_col='pct', val_pct=0.2):\n",
    "    \"\"\"\n",
    "    return training and validation data and y_pred\n",
    "    \n",
    "    period: how long we want the x values to go back\n",
    "    x_col: all columns of potential features\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    train_index, val_index = get_ordered_index(df, period_to_skip=period+1, val_pct=0.2)\n",
    "\n",
    "    y_train = np.array(df.loc[train_index, y_col])\n",
    "    y_val = np.array(df.loc[val_index, y_col])\n",
    "    \n",
    "    x_train = np.zeros((len(train_index), len(x_col), period))\n",
    "    x_val = np.zeros((len(val_index), len(x_col), period))\n",
    "    \n",
    "    for j in range(len(x_col)):\n",
    "        x_column = x_col[j]\n",
    "\n",
    "        for i, train_i in enumerate(train_index):\n",
    "            temp = np.array(get_x(df, train_i, x_col = x_column, period=period))\n",
    "            x_train[i, j, :] = temp\n",
    "\n",
    "        for i, val_i in enumerate(val_index):\n",
    "            temp = np.array(get_x(df, val_i, x_col = x_column, period=period))\n",
    "            x_val[i, j, :] = temp\n",
    "\n",
    "    # return np.squeeze(x_train), y_train, np.squeeze(x_val), y_val\n",
    "    return x_train, np.expand_dims(y_train,1), x_val, np.expand_dims(y_val,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f44a63ff-c89f-4c56-a9f8-fc847ea71ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tensor(x):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    return [torch.tensor(i).to(device).type(torch.cuda.FloatTensor) for i in x]\n",
    "\n",
    "temp = get_xy(df, 14, x_col = [\"pct\", 'ema_pct_21',\"ema_pct_200\"], y_col='y_binary_sma5', val_pct=0.2)\n",
    "x_train, y_train, x_val, y_val = convert_to_tensor(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "4948ad0a-0797-494f-b49e-77a535356231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3985, 3, 14]), torch.Size([3985, 1]))"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e855af5-a9bc-417f-8fdf-56bb5702697d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turning data into a dataloader\n",
    "\n",
    "batch_size = 64\n",
    "x_train_ds = CustomDataset(x_train, y_train)\n",
    "x_val_ds = CustomDataset(x_val, y_val)\n",
    "train_dataloader = DataLoader(x_train_ds, batch_size=batch_size, shuffle=True, generator=torch.Generator(device=device))\n",
    "val_dataloader = DataLoader(x_val_ds, batch_size=batch_size, shuffle=True, generator=torch.Generator(device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "df9bdfa3-fd2f-4ccd-9cef-1144552901b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 3, 14]),\n",
       " 64,\n",
       " tensor([[-0.0054,  0.0135,  0.0082,  0.0047,  0.0182, -0.0158, -0.0147, -0.0271,\n",
       "           0.0304, -0.0019, -0.0225, -0.0063,  0.0062,  0.0188],\n",
       "         [ 0.0006,  0.0018,  0.0024,  0.0026,  0.0041,  0.0022,  0.0006, -0.0019,\n",
       "           0.0010,  0.0007, -0.0014, -0.0019, -0.0012,  0.0006],\n",
       "         [ 0.0015,  0.0016,  0.0017,  0.0017,  0.0019,  0.0017,  0.0015,  0.0012,\n",
       "           0.0015,  0.0015,  0.0012,  0.0011,  0.0012,  0.0013]]),\n",
       " tensor([1.]))"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking data shapes\n",
    "\n",
    "temp = next(iter(train_dataloader))\n",
    "temp[0].shape, temp[1].shape[0], temp[0][1, :, :], temp[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e6a7e951-7113-4ca2-8d7a-1fdff2a35267",
   "metadata": {},
   "outputs": [],
   "source": [
    "class indicator_cnn(nn.Module):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        super(indicator_cnn, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=3, out_channels=6, kernel_size=5, stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv1d(6, 16, 3)\n",
    "        self.fc1 = nn.Linear(16 * 8, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def predict(self, x, return_logits=True, threshold = 0.5):\n",
    "        logits = torch.sigmoid(self.forward(x).numpy())\n",
    "        if return_logits:\n",
    "            return logits\n",
    "        return (logits > threshold).astype(\"int\")\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "model = indicator_cnn().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8fc16817-7f84-400d-80a5-80092eb000ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, betas = (0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "2a9aab76-bd62-4915-be81-265e31c50c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using tensorboard visualisation tool\n",
    "# To view, start TensorBoard on the command line with:\n",
    "#tensorboard --logdir=runs\n",
    "#and open a browser tab to http://localhost:6006/\n",
    "from datetime import datetime\n",
    "\n",
    "writer = SummaryWriter('runs/basic_indicator_cnn')\n",
    "epoch_number = 0\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a1f889b7-ec3c-4961-a18b-a2dd4c54fd05",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 ------------------------>  Avg training loss: 0.009772, Avg val loss: 0.011362, Validation accuracy: 53.5% \n",
      "\n",
      "Epoch 2 ------------------------>  Avg training loss: 0.009723, Avg val loss: 0.011391, Validation accuracy: 54.2% \n",
      "\n",
      "Epoch 3 ------------------------>  Avg training loss: 0.009738, Avg val loss: 0.011379, Validation accuracy: 54.6% \n",
      "\n",
      "Epoch 4 ------------------------>  Avg training loss: 0.009667, Avg val loss: 0.011366, Validation accuracy: 55.5% \n",
      "\n",
      "Epoch 5 ------------------------>  Avg training loss: 0.009681, Avg val loss: 0.011386, Validation accuracy: 54.1% \n",
      "\n",
      "Epoch 6 ------------------------>  Avg training loss: 0.009642, Avg val loss: 0.011357, Validation accuracy: 54.6% \n",
      "\n",
      "Epoch 7 ------------------------>  Avg training loss: 0.009609, Avg val loss: 0.011450, Validation accuracy: 53.5% \n",
      "\n",
      "Epoch 8 ------------------------>  Avg training loss: 0.009631, Avg val loss: 0.011412, Validation accuracy: 53.0% \n",
      "\n",
      "Epoch 9 ------------------------>  Avg training loss: 0.009579, Avg val loss: 0.011355, Validation accuracy: 54.8% \n",
      "\n",
      "Epoch 10 ------------------------>  Avg training loss: 0.009604, Avg val loss: 0.011484, Validation accuracy: 54.0% \n",
      "\n",
      "Epoch 11 ------------------------>  Avg training loss: 0.009567, Avg val loss: 0.011461, Validation accuracy: 53.5% \n",
      "\n",
      "Epoch 12 ------------------------>  Avg training loss: 0.009491, Avg val loss: 0.011616, Validation accuracy: 54.2% \n",
      "\n",
      "Epoch 13 ------------------------>  Avg training loss: 0.009534, Avg val loss: 0.011577, Validation accuracy: 54.2% \n",
      "\n",
      "Epoch 14 ------------------------>  Avg training loss: 0.009490, Avg val loss: 0.011545, Validation accuracy: 53.6% \n",
      "\n",
      "Epoch 15 ------------------------>  Avg training loss: 0.009460, Avg val loss: 0.011504, Validation accuracy: 55.2% \n",
      "\n",
      "Epoch 16 ------------------------>  Avg training loss: 0.009469, Avg val loss: 0.011515, Validation accuracy: 54.8% \n",
      "\n",
      "Epoch 17 ------------------------>  Avg training loss: 0.009492, Avg val loss: 0.011615, Validation accuracy: 56.1% \n",
      "\n",
      "Epoch 18 ------------------------>  Avg training loss: 0.009492, Avg val loss: 0.011685, Validation accuracy: 53.0% \n",
      "\n",
      "Epoch 19 ------------------------>  Avg training loss: 0.009418, Avg val loss: 0.011643, Validation accuracy: 53.1% \n",
      "\n",
      "Epoch 20 ------------------------>  Avg training loss: 0.009404, Avg val loss: 0.011655, Validation accuracy: 54.8% \n",
      "\n",
      "Epoch 21 ------------------------>  Avg training loss: 0.009377, Avg val loss: 0.011506, Validation accuracy: 54.2% \n",
      "\n",
      "Epoch 22 ------------------------>  Avg training loss: 0.009349, Avg val loss: 0.011692, Validation accuracy: 54.8% \n",
      "\n",
      "Epoch 23 ------------------------>  Avg training loss: 0.009299, Avg val loss: 0.011593, Validation accuracy: 54.7% \n",
      "\n",
      "Epoch 24 ------------------------>  Avg training loss: 0.009273, Avg val loss: 0.011597, Validation accuracy: 52.5% \n",
      "\n",
      "Epoch 25 ------------------------>  Avg training loss: 0.009319, Avg val loss: 0.011651, Validation accuracy: 53.7% \n",
      "\n",
      "Epoch 26 ------------------------>  Avg training loss: 0.009282, Avg val loss: 0.011688, Validation accuracy: 54.1% \n",
      "\n",
      "Epoch 27 ------------------------>  Avg training loss: 0.009272, Avg val loss: 0.011553, Validation accuracy: 53.4% \n",
      "\n",
      "Epoch 28 ------------------------>  Avg training loss: 0.009261, Avg val loss: 0.011615, Validation accuracy: 54.5% \n",
      "\n",
      "Epoch 29 ------------------------>  Avg training loss: 0.009193, Avg val loss: 0.011704, Validation accuracy: 52.9% \n",
      "\n",
      "Epoch 30 ------------------------>  Avg training loss: 0.009152, Avg val loss: 0.011750, Validation accuracy: 51.3% \n",
      "\n",
      "Epoch 31 ------------------------>  Avg training loss: 0.009161, Avg val loss: 0.011746, Validation accuracy: 52.8% \n",
      "\n",
      "Epoch 32 ------------------------>  Avg training loss: 0.009108, Avg val loss: 0.011777, Validation accuracy: 54.0% \n",
      "\n",
      "Epoch 33 ------------------------>  Avg training loss: 0.009121, Avg val loss: 0.011726, Validation accuracy: 51.8% \n",
      "\n",
      "Epoch 34 ------------------------>  Avg training loss: 0.009053, Avg val loss: 0.011664, Validation accuracy: 54.2% \n",
      "\n",
      "Epoch 35 ------------------------>  Avg training loss: 0.009045, Avg val loss: 0.011810, Validation accuracy: 52.9% \n",
      "\n",
      "Epoch 36 ------------------------>  Avg training loss: 0.009030, Avg val loss: 0.011827, Validation accuracy: 50.9% \n",
      "\n",
      "Epoch 37 ------------------------>  Avg training loss: 0.008998, Avg val loss: 0.011832, Validation accuracy: 53.2% \n",
      "\n",
      "Epoch 38 ------------------------>  Avg training loss: 0.009006, Avg val loss: 0.011943, Validation accuracy: 51.9% \n",
      "\n",
      "Epoch 39 ------------------------>  Avg training loss: 0.009005, Avg val loss: 0.011777, Validation accuracy: 49.7% \n",
      "\n",
      "Epoch 40 ------------------------>  Avg training loss: 0.008997, Avg val loss: 0.011783, Validation accuracy: 52.2% \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1} ------------------------>  \", end='')\n",
    "    avg_loss = train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    avg_vloss, correct = test_loop(validation_dataloader, model, loss_fn, batch_size=64)\n",
    "    \n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    t + 1)\n",
    "    writer.flush()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c8e57b-36f6-4756-b328-16a8b2aae47c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trading_environment",
   "language": "python",
   "name": "trading_environment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
